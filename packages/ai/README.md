# AI

This package provides a client for interacting with OpenAI's API, allowing you
to send prompts and receive responses in a structured manner.

## Content

1. [Overview](#overview)
2. [Environment Variables](#environment-variables)
3. [Prompts](#prompts)
4. [Types](#types)
   - [AIRole](#airole)
   - [MessageHistoryType](#messagehistorytype)
   - [OpenAIChatModel](#openaichatmodel)
5. [Usage in the Application](#usage-in-the-application)
6. [Functional Example](#functional-example)

## Overview

The `OpenAIClient` class offers a streamlined approach to managing interactions
with OpenAI's API. It manages the conversation history and provides a method for
sending prompts and receiving responses.

### Key Features:

- Maintain conversation history with different roles (user, assistant, system).
- Easily send prompts and receive structured responses from OpenAI.
- Support for dynamic configuration through environment variables.

## Environment Variables

To configure the OpenAI client, you need to set the following environment
variables:

- **OPENAI_API_KEY**: Your OpenAI API key for authentication.
- **OPENAI_DEFAULT_MODEL** _(optional)_: The default model to use when none is
  specified; if the value is not set, it will fallback to `gpt-4o-mini`.

Example `.env` file:

```shell
OPENAI_API_KEY=sk-1234567890abcdef1234567890abcdef
OPENAI_DEFAULT_MODEL=gpt-4o-mini
```

## Prompts

Prompts are defined under the `src/prompts/*` directory. Here’s an example
prompt:

```ts
export const RecipeExamplePrompts = {
  config: `You are a recipe assistant. Your job is to extract the main ingredients and steps from a recipe. Only provide the requested information, without introductions or additional commentary. As a recipe assistant, your goal is to give a quick, clear list of ingredients and steps.`,
  recipePrompt: `Please extract and list the main ingredients and cooking steps from the following recipe. Present them in bullet points.`,
};
```

## Types

### AIRole

Represents the role of a participant in the conversation. Possible values
include:

- **'system'**: The system message that sets the behavior of the assistant.
- **'user'**: Messages sent by the user.
- **'assistant'**: Responses generated by the assistant.

### MessageHistoryType

Defines the structure of a message in the conversation history, which includes:

- **role**: The role of the message sender (AI role).
- **content**: The actual message content.

### OpenAIChatModel

Represents the model used for chat completions. It indicates which version of
the OpenAI model to use when sending prompts.

## Usage in the Application

To integrate the OpenAI Client into your application, follow these steps:

1. **Instantiate the Client**: Create an instance of the `OpenAIClient` class.
   You can provide an optional system configuration prompt and a default model.
   If you don’t specify these, the client will initialize without a system
   prompt and will use the default model specified in your environment variables
   or fallback to `gpt-4o-mini`.

   ```ts
   // Example with custom system prompt and model
   const client = new OpenAIClient({
     systemPrompt: 'Your system prompt here',
     model: 'gpt-4',
   });

   // Example without custom prompt, using the default model
   const client = new OpenAIClient({ systemPrompt: 'Your system prompt here' });

   // Example without custom model but no system prompt
   const client = new OpenAIClient({ model: 'gpt-4' });
   ```

2. **Send a Prompt**: Use the `sendPrompt` method to send a prompt and receive a
   response.

   ```ts
   const response = await client.sendPrompt({
     prompt: 'Your prompt here',
     content: 'Additional context if needed',
   });
   ```

3. **Manage Response**: Use the string (response) given by the method. The
   client automatically manages message history, allowing for contextually
   relevant interactions.

## Functional Example

To see a functional example of how to use the OpenAI Client, you can run the
following command:

```shell
yarn openai:example
```

This command will run an example implementation located in `example.ts` at the
root of the package, showcasing how to effectively use the client in a practical
scenario."
